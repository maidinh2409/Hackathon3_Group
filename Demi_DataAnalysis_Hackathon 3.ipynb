{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0a4f73-d295-4e30-820e-3b7a66b47a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total responses: 1001\n",
      "Columns: 124\n",
      "Open-ended questions: 48\n",
      "\n",
      "Q2_Experience_with_AI_animal_other_OE_sentiment_percentage:\n",
      "count    112.000000\n",
      "mean       0.837954\n",
      "std        0.187040\n",
      "min        0.339674\n",
      "25%        0.692079\n",
      "50%        0.937590\n",
      "75%        0.996153\n",
      "max        0.999776\n",
      "Name: Q2_Experience_with_AI_animal_other_OE_sentiment_percentage, dtype: float64\n",
      "\n",
      "Q4A_Sector_AI_making_a_positive_impact_other_OE_sentiment_percentage:\n",
      "count    81.000000\n",
      "mean      0.879611\n",
      "std       0.164659\n",
      "min       0.458046\n",
      "25%       0.769937\n",
      "50%       0.984473\n",
      "75%       0.995199\n",
      "max       0.998966\n",
      "Name: Q4A_Sector_AI_making_a_positive_impact_other_OE_sentiment_percentage, dtype: float64\n",
      "\n",
      "Q4B_Sector_AI_making_a_negative_impact_other_OE_sentiment_percentage:\n",
      "count    81.000000\n",
      "mean      0.898728\n",
      "std       0.132974\n",
      "min       0.465820\n",
      "25%       0.825016\n",
      "50%       0.964309\n",
      "75%       0.994571\n",
      "max       0.999315\n",
      "Name: Q4B_Sector_AI_making_a_negative_impact_other_OE_sentiment_percentage, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('Hackathon round 3 with demos[48].csv')\n",
    "\n",
    "# Quick exploration\n",
    "print(f\"Total responses: {len(df)}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "\n",
    "# Find open-ended responses\n",
    "oe_columns = [col for col in df.columns if '_OE' in col]\n",
    "print(f\"Open-ended questions: {len(oe_columns)}\")\n",
    "\n",
    "# Look at sentiment distribution\n",
    "sentiment_cols = [col for col in df.columns if 'sentiment' in col and 'percentage' in col]\n",
    "for col in sentiment_cols[:3]:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2c14e5-e5a2-47ff-8192-2490102fd12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■ BC AI Survey Data Explorer\n",
      "==================================================\n",
      "■ Loading survey data...\n",
      "■ Loaded 1001 responses with 124 columns\n",
      "\n",
      "■ Dataset Overview:\n",
      "   • Total responses: 1,001\n",
      "   • Total columns: 124\n",
      "   • Response rate: ~1001 out of 1,001 target\n",
      "\n",
      "■ Column Categories:\n",
      "   • Open-ended responses (_OE): 16\n",
      "   • Sentiment scores: 16\n",
      "   • Demographic fields: 3\n",
      "\n",
      "■ Demographics Snapshot:\n",
      "   • 55 Plus: 423 (42.3%)\n",
      "   • 35-54: 348 (34.8%)\n",
      "   • 18-34: 230 (23.0%)\n",
      "\n",
      "■ Geographic Distribution:\n",
      "   • Vancouver / Lower Mainland: 767 (76.6%)\n",
      "   • Victoria: 137 (13.7%)\n",
      "   • Kelowna: 67 (6.7%)\n",
      "   • Prince George: 30 (3.0%)\n",
      "\n",
      "■ AI Experience Levels:\n",
      "   • Occasional user – I’ve tried a few tools like ChatGPT or an AI art app.: 405 (40.5%)\n",
      "   • Aware but not a user – I’ve heard about AI but haven’t used it myself.: 316 (31.6%)\n",
      "   • Regular user – I use AI often for work or personal stuff.: 164 (16.4%)\n",
      "   • No experience – I haven’t really used AI and don’t know much about it.: 106 (10.6%)\n",
      "   • Expert/Developer – I work with or build AI tools.: 10 (1.0%)\n",
      "\n",
      "■ Sample Quotes (Open-Ended Responses):\n",
      "   (These are the storytelling goldmines!)\n",
      "\n",
      "   ■ Advice to BC Leaders (Q17):\n",
      "      1. \"People need to survive\"\n",
      "      2. \"Expand the thinking and possibilities of artificial intellience\"\n",
      "      3. \"Focus on ethical use and promotion of AI. It's here whether we like it or not so...\"\n",
      "      ... and 990 more responses!\n",
      "\n",
      "■ Sentiment Patterns:\n",
      "   • Average sentiment (Q17): 0.61 (0=negative, 1=positive)\n",
      "   • Very negative responses (<0.1): 0\n",
      "   • Very positive responses (>0.9): 0\n",
      "\n",
      "■ Ready to Dive Deeper?\n",
      "\n",
      "   ■ Hot Tips for Exploration:\n",
      "   1. Focus on open-ended columns (*_OE) for authentic quotes\n",
      "   2. Cross-reference sentiment with demographics\n",
      "   3. Look for patterns in AI experience vs attitudes\n",
      "   4. Hunt for geographic differences (Vancouver vs rural)\n",
      "   5. Find the extreme voices (99%+ positive/negative sentiment)\n",
      "\n",
      "   ■ Suggested Next Steps:\n",
      "   • Load data: df = pd.read_csv('Hackathon round 3 with demos[48].csv')\n",
      "   • Explore quotes: df['Q17_Advice_BC_Leaders_text_OE'].dropna()\n",
      "   • Check sentiment: df['Q17_Advice_BC_Leaders_text_OE_sentiment_percentage']\n",
      "   • Filter by demographics: df[df['AgeRollup_Broad'] == '18-34']\n",
      "   • Find patterns: df.groupby('Q1_Experience_with_AI')['sentiment_col'].mean()\n",
      "\n",
      "■ Happy Data Storytelling!\n",
      "   Remember: Every row is a real British Columbian's voice.\n",
      "   Your job is to help those voices be heard!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "BC AI Survey Data Explorer - Hackathon Starter Script\n",
    "=====================================================\n",
    "\n",
    "A friendly introduction to the BC AI Survey dataset.\n",
    "Perfect for getting started with data exploration!\n",
    "\n",
    "Usage:\n",
    "    python explore-data-starter.py\n",
    "\n",
    "Requirements:\n",
    "    pip install pandas\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def explore_bc_ai_survey():\n",
    "    \"\"\"Explore the BC AI Survey data with helpful guidance\"\"\"\n",
    "    \n",
    "    # Find the data file\n",
    "    data_file = \"Hackathon round 3 with demos[48].csv\"\n",
    "    if not Path(data_file).exists():\n",
    "        print(f\"■ Data file not found: {data_file}\")\n",
    "        print(\"Make sure you're running this script from the repository root directory.\")\n",
    "        return\n",
    "    \n",
    "    print(\"■ BC AI Survey Data Explorer\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Load the data\n",
    "        print(\"■ Loading survey data...\")\n",
    "        df = pd.read_csv(data_file)\n",
    "        print(f\"■ Loaded {len(df)} responses with {len(df.columns)} columns\")\n",
    "        print()\n",
    "        \n",
    "        # Basic overview\n",
    "        print(\"■ Dataset Overview:\")\n",
    "        print(f\"   • Total responses: {len(df):,}\")\n",
    "        print(f\"   • Total columns: {len(df.columns):,}\")\n",
    "        print(f\"   • Response rate: ~{len(df)} out of 1,001 target\")\n",
    "        print()\n",
    "        \n",
    "        # Find key column types\n",
    "        oe_columns = [col for col in df.columns if '_OE' in col and 'sentiment' not in col]\n",
    "        sentiment_columns = [col for col in df.columns if 'sentiment_percentage' in col]\n",
    "        demo_columns = ['AgeRollup_Broad', 'Q1_Location_in_BC', 'Q1_Experience_with_AI']\n",
    "        \n",
    "        print(\"■ Column Categories:\")\n",
    "        print(f\"   • Open-ended responses (_OE): {len(oe_columns)}\")\n",
    "        print(f\"   • Sentiment scores: {len(sentiment_columns)}\")\n",
    "        print(f\"   • Demographic fields: {len(demo_columns)}\")\n",
    "        print()\n",
    "        \n",
    "        # Demographics snapshot\n",
    "        print(\"■ Demographics Snapshot:\")\n",
    "        if 'AgeRollup_Broad' in df.columns:\n",
    "            age_dist = df['AgeRollup_Broad'].value_counts()\n",
    "            for age, count in age_dist.items():\n",
    "                pct = (count / len(df)) * 100\n",
    "                print(f\"   • {age}: {count} ({pct:.1f}%)\")\n",
    "        print()\n",
    "        \n",
    "        if 'Q1_Location_in_BC' in df.columns:\n",
    "            print(\"■ Geographic Distribution:\")\n",
    "            location_dist = df['Q1_Location_in_BC'].value_counts().head(5)\n",
    "            for location, count in location_dist.items():\n",
    "                pct = (count / len(df)) * 100\n",
    "                print(f\"   • {location}: {count} ({pct:.1f}%)\")\n",
    "        print()\n",
    "        \n",
    "        # AI Experience levels\n",
    "        if 'Q1_Experience_with_AI' in df.columns:\n",
    "            print(\"■ AI Experience Levels:\")\n",
    "            exp_dist = df['Q1_Experience_with_AI'].value_counts()\n",
    "            for exp, count in exp_dist.items():\n",
    "                pct = (count / len(df)) * 100\n",
    "                print(f\"   • {exp}: {count} ({pct:.1f}%)\")\n",
    "        print()\n",
    "        \n",
    "        # Sample some interesting quotes\n",
    "        print(\"■ Sample Quotes (Open-Ended Responses):\")\n",
    "        print(\"   (These are the storytelling goldmines!)\")\n",
    "        print()\n",
    "        \n",
    "        # Q17 Advice to leaders\n",
    "        if 'Q17_Advice_BC_Leaders_text_OE' in df.columns:\n",
    "            q17_responses = df['Q17_Advice_BC_Leaders_text_OE'].dropna()\n",
    "            print(\"   ■ Advice to BC Leaders (Q17):\")\n",
    "            for i, response in enumerate(q17_responses.head(3)):\n",
    "                if len(response.strip()) > 10:\n",
    "                    preview = response[:80] + \"...\" if len(response) > 80 else response\n",
    "                    print(f\"      {i+1}. \\\"{preview}\\\"\")\n",
    "            print(f\"      ... and {len(q17_responses)-3:,} more responses!\")\n",
    "            print()\n",
    "        \n",
    "        # Sentiment patterns\n",
    "        print(\"■ Sentiment Patterns:\")\n",
    "        sample_sentiment_col = [col for col in sentiment_columns if 'Q17' in col]\n",
    "        if sample_sentiment_col:\n",
    "            col = sample_sentiment_col[0]\n",
    "            sentiment_scores = pd.to_numeric(df[col], errors='coerce').dropna()\n",
    "            avg_sentiment = sentiment_scores.mean()\n",
    "            print(f\"   • Average sentiment (Q17): {avg_sentiment:.2f} (0=negative, 1=positive)\")\n",
    "            \n",
    "            # Find extreme sentiments\n",
    "            very_negative = sentiment_scores[sentiment_scores < 0.1]\n",
    "            very_positive = sentiment_scores[sentiment_scores > 0.9]\n",
    "            print(f\"   • Very negative responses (<0.1): {len(very_negative)}\")\n",
    "            print(f\"   • Very positive responses (>0.9): {len(very_positive)}\")\n",
    "        print()\n",
    "        \n",
    "        # Next steps guidance\n",
    "        print(\"■ Ready to Dive Deeper?\")\n",
    "        print()\n",
    "        print(\"   ■ Hot Tips for Exploration:\")\n",
    "        print(\"   1. Focus on open-ended columns (*_OE) for authentic quotes\")\n",
    "        print(\"   2. Cross-reference sentiment with demographics\")\n",
    "        print(\"   3. Look for patterns in AI experience vs attitudes\")\n",
    "        print(\"   4. Hunt for geographic differences (Vancouver vs rural)\")\n",
    "        print(\"   5. Find the extreme voices (99%+ positive/negative sentiment)\")\n",
    "        print()\n",
    "        \n",
    "        print(\"   ■ Suggested Next Steps:\")\n",
    "        print(\"   • Load data: df = pd.read_csv('Hackathon round 3 with demos[48].csv')\")\n",
    "        print(\"   • Explore quotes: df['Q17_Advice_BC_Leaders_text_OE'].dropna()\")\n",
    "        print(\"   • Check sentiment: df['Q17_Advice_BC_Leaders_text_OE_sentiment_percentage']\")\n",
    "        print(\"   • Filter by demographics: df[df['AgeRollup_Broad'] == '18-34']\")\n",
    "        print(\"   • Find patterns: df.groupby('Q1_Experience_with_AI')['sentiment_col'].mean()\")\n",
    "        print()\n",
    "        \n",
    "        print(\"■ Happy Data Storytelling!\")\n",
    "        print(\"   Remember: Every row is a real British Columbian's voice.\")\n",
    "        print(\"   Your job is to help those voices be heard!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"■ Error loading data: {e}\")\n",
    "        print(\"Make sure pandas is installed: pip install pandas\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    explore_bc_ai_survey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59dcfa46-3a27-44c2-a79e-883c567450ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Hackathon round 3 with demos[48].csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60d3ab8-35ea-4c09-8d14-3eba676a099a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  People need to survive\n",
       "1       Expand the thinking and possibilities of artif...\n",
       "2       Focus on ethical use and promotion of AI. It's...\n",
       "3                            Don't let it take jobs away \n",
       "4       My ideal would be to disband the NDP, but as t...\n",
       "                              ...                        \n",
       "996                       encourage use in Health matters\n",
       "997                                    We don’t need AI. \n",
       "998                         Carefully monitor and control\n",
       "999     Since I do not know anything about it , I’m in...\n",
       "1000    Keep bc working. Rejig elections canada. There...\n",
       "Name: Q17_Advice_BC_Leaders_text_OE, Length: 993, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Q17_Advice_BC_Leaders_text_OE'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1ff883-49b8-47af-9421-ed5500a9671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Word  Frequency\n",
      "0           and        503\n",
      "1            to        446\n",
      "2           the        439\n",
      "3            it        394\n",
      "4            ai        286\n",
      "5            be        244\n",
      "6            of        241\n",
      "7           not        168\n",
      "8           for        159\n",
      "9            in        158\n",
      "10           is        148\n",
      "11            a        147\n",
      "12         make        125\n",
      "13           on        115\n",
      "14         that        113\n",
      "15          use        113\n",
      "16       people        110\n",
      "17         dont        104\n",
      "18         with         97\n",
      "19           do         79\n",
      "20         sure         76\n",
      "21         have         72\n",
      "22          are         71\n",
      "23          all         68\n",
      "24        don’t         67\n",
      "25           as         67\n",
      "26           we         65\n",
      "27          its         65\n",
      "28            i         62\n",
      "29         this         59\n",
      "30       should         57\n",
      "31           or         57\n",
      "32         will         55\n",
      "33          let         55\n",
      "34         from         50\n",
      "35          you         48\n",
      "36          how         48\n",
      "37          out         48\n",
      "38           no         45\n",
      "39         keep         44\n",
      "40          can         44\n",
      "41         need         44\n",
      "42         take         43\n",
      "43          our         43\n",
      "44          but         43\n",
      "45          get         41\n",
      "46  regulations         41\n",
      "47        think         40\n",
      "48        about         39\n",
      "49     everyone         39\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def count_words_fast(text):\n",
    "    text = text.lower()\n",
    "    skips = [\".\", \",\", \":\", \";\", \"'\", '\"']\n",
    "    for ch in skips:\n",
    "        text = text.replace(ch, \"\")\n",
    "    word_counts = Counter(text.split())\n",
    "    return word_counts\n",
    "\n",
    "# Combine all responses into one large string\n",
    "all_text = \" \".join(df['Q17_Advice_BC_Leaders_text_OE'].dropna().tolist())\n",
    "\n",
    "# Count word frequency\n",
    "word_freq = count_words_fast(all_text)\n",
    "\n",
    "# Convert to a sorted DataFrame for display\n",
    "word_freq_df = pd.DataFrame(word_freq.items(), columns=['Word', 'Frequency'])\n",
    "word_freq_df = word_freq_df.sort_values(by='Frequency', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display top 20 most common words\n",
    "print(word_freq_df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a9ab52-02ec-4d8c-96d5-f17e1e116f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d478db-2352-4506-8346-80be454a12f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Word  Frequency\n",
      "4            ai        286\n",
      "12         make        125\n",
      "15          use        113\n",
      "16       people        110\n",
      "17         dont        104\n",
      "20         sure         76\n",
      "24        don’t         67\n",
      "33          let         55\n",
      "39         keep         44\n",
      "41         need         44\n",
      "42         take         43\n",
      "45          get         41\n",
      "46  regulations         41\n",
      "47        think         40\n",
      "49     everyone         39\n",
      "50     regulate         39\n",
      "51         jobs         38\n",
      "55       public         36\n",
      "59         good         35\n",
      "61         know         32\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_df = word_freq_df[~word_freq_df['Word'].isin(stop_words)]\n",
    "\n",
    "# Xem top từ mang ý nghĩa\n",
    "print(filtered_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41433e57-bdd7-4eb4-bd58-e29864c64e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■ Word Frequency by Age Group (Q17 Responses)\n",
      "==================================================\n",
      "\n",
      " Age Group: 18-34\n",
      "   • ai: 81\n",
      "   • dont: 47\n",
      "   • make: 35\n",
      "   • people: 32\n",
      "   • use: 32\n",
      "   • sure: 14\n",
      "   • let: 13\n",
      "   • regulate: 13\n",
      "   • good: 13\n",
      "   • stop: 12\n",
      "\n",
      " Age Group: 55 Plus\n",
      "   • ai: 103\n",
      "   • dont: 55\n",
      "   • make: 42\n",
      "   • people: 39\n",
      "   • use: 37\n",
      "   • sure: 30\n",
      "   • think: 20\n",
      "   • get: 20\n",
      "   • keep: 20\n",
      "   • careful: 19\n",
      "\n",
      " Age Group: 35-54\n",
      "   • ai: 102\n",
      "   • dont: 69\n",
      "   • make: 48\n",
      "   • use: 46\n",
      "   • people: 39\n",
      "   • sure: 33\n",
      "   • let: 25\n",
      "   • jobs: 21\n",
      "   • regulations: 21\n",
      "   • take: 20\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "print(\"■ Word Frequency by Age Group (Q17 Responses)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'Q17_Advice_BC_Leaders_text_OE' in df.columns and 'AgeRollup_Broad' in df.columns:\n",
    "    age_groups = df['AgeRollup_Broad'].dropna().unique()\n",
    "    \n",
    "    for age_group in age_groups:\n",
    "        print(f\"\\n Age Group: {age_group}\")\n",
    "        subset = df[(df['AgeRollup_Broad'] == age_group) & (df['Q17_Advice_BC_Leaders_text_OE'].notna())]\n",
    "        texts = subset['Q17_Advice_BC_Leaders_text_OE'].apply(clean_text)\n",
    "        all_text = \" \".join(texts)\n",
    "        word_freq = Counter(all_text.split())\n",
    "        \n",
    "        # Loại bỏ từ dừng\n",
    "        filtered = {w: c for w, c in word_freq.items() if w not in stop_words}\n",
    "        top_words = sorted(filtered.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        \n",
    "        for word, count in top_words:\n",
    "            print(f\"   • {word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "475fea9e-2c2a-4ab2-9345-dbd96649c349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "■ Word Frequency by Region (Q17 Responses)\n",
      "==================================================\n",
      "\n",
      " Region: Vancouver / Lower Mainland\n",
      "   • ai: 213\n",
      "   • dont: 136\n",
      "   • make: 95\n",
      "   • people: 89\n",
      "   • use: 85\n",
      "   • sure: 55\n",
      "   • let: 48\n",
      "   • keep: 35\n",
      "   • take: 33\n",
      "   • think: 33\n",
      "\n",
      " Region: Victoria\n",
      "   • ai: 51\n",
      "   • dont: 27\n",
      "   • make: 18\n",
      "   • use: 17\n",
      "   • sure: 14\n",
      "   • people: 13\n",
      "   • regulate: 9\n",
      "   • get: 7\n",
      "   • everyone: 7\n",
      "   • accessible: 6\n",
      "\n",
      " Region: Kelowna\n",
      "   • make: 10\n",
      "   • ai: 9\n",
      "   • sure: 8\n",
      "   • use: 7\n",
      "   • need: 6\n",
      "   • dont: 5\n",
      "   • monitor: 4\n",
      "   • public: 4\n",
      "   • ethical: 4\n",
      "   • everyone: 4\n",
      "\n",
      " Region: Prince George\n",
      "   • ai: 13\n",
      "   • use: 6\n",
      "   • people: 6\n",
      "   • get: 5\n",
      "   • find: 5\n",
      "   • human: 4\n",
      "   • everyone: 4\n",
      "   • good: 3\n",
      "   • public: 3\n",
      "   • dont: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"■ Word Frequency by Region (Q17 Responses)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    return text.strip()\n",
    "\n",
    "# Lấy top 5 vùng xuất hiện nhiều nhất\n",
    "top_regions = df['Q1_Location_in_BC'].value_counts().head(5).index.tolist()\n",
    "\n",
    "for region in top_regions:\n",
    "    print(f\"\\n Region: {region}\")\n",
    "    subset = df[(df['Q1_Location_in_BC'] == region) & (df['Q17_Advice_BC_Leaders_text_OE'].notna())]\n",
    "    texts = subset['Q17_Advice_BC_Leaders_text_OE'].apply(clean_text)\n",
    "    all_text = \" \".join(texts)\n",
    "    word_freq = Counter(all_text.split())\n",
    "\n",
    "    # Lọc stopwords\n",
    "    filtered = {w: c for w, c in word_freq.items() if w not in stop_words}\n",
    "    top_words = sorted(filtered.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    for word, count in top_words:\n",
    "        print(f\"   • {word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "670abcf9-6e47-4bfd-98dc-ca679fa3e6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.553198\n",
      "1    0.570897\n",
      "2    0.888593\n",
      "3    0.524501\n",
      "4    0.456881\n",
      "Name: Q17_Advice_BC_Leaders_text_OE_sentiment_percentage, dtype: float64\n",
      "count    997.000000\n",
      "mean       0.713045\n",
      "std        0.182151\n",
      "min        0.288424\n",
      "25%        0.560119\n",
      "50%        0.705587\n",
      "75%        0.877080\n",
      "max        0.999290\n",
      "Name: Q17_Advice_BC_Leaders_text_OE_sentiment_percentage, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['Q17_Advice_BC_Leaders_text_OE_sentiment_percentage'].head())\n",
    "\n",
    "print(df['Q17_Advice_BC_Leaders_text_OE_sentiment_percentage'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80965555-bdff-4bdd-a038-ced5f6b8c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average sentiment for age 18-34: 0.713\n"
     ]
    }
   ],
   "source": [
    "age_group = '18-34'\n",
    "subset = df[df['AgeRollup_Broad'] == age_group]\n",
    "sentiments = pd.to_numeric(subset['Q17_Advice_BC_Leaders_text_OE_sentiment_percentage'], errors='coerce').dropna()\n",
    "\n",
    "print(f\" Average sentiment for age {age_group}: {sentiments.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6afa7dd5-a9ed-4af1-971a-180eb65baa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average sentiment by AI experience level:\n",
      "Q1_Experience_with_AI\n",
      "Regular user – I use AI often for work or personal stuff.                  0.735705\n",
      "Aware but not a user – I’ve heard about AI but haven’t used it myself.     0.717028\n",
      "No experience – I haven’t really used AI and don’t know much about it.     0.711189\n",
      "Occasional user – I’ve tried a few tools like ChatGPT or an AI art app.    0.703087\n",
      "Expert/Developer – I work with or build AI tools.                          0.643874\n",
      "Name: Q17_Advice_BC_Leaders_text_OE_sentiment_percentage, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['Q17_Advice_BC_Leaders_text_OE_sentiment_percentage'] = pd.to_numeric(\n",
    "    df['Q17_Advice_BC_Leaders_text_OE_sentiment_percentage'], errors='coerce'\n",
    ")\n",
    "\n",
    "sentiment_by_ai_exp = df.groupby('Q1_Experience_with_AI')['Q17_Advice_BC_Leaders_text_OE_sentiment_percentage'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\" Average sentiment by AI experience level:\")\n",
    "print(sentiment_by_ai_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7316accf-1f07-4bbb-986f-44b182de272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "very_positive = df[df['Q17_Advice_BC_Leaders_text_OE_sentiment_percentage'] > 0.9]\n",
    "very_negative = df[df['Q17_Advice_BC_Leaders_text_OE_sentiment_percentage'] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "474545f1-bdab-4661-962f-a48e56ae2d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Cluster 0\n",
      "   - I dont think AI is a good thing when it takes away peoples ability to think for themselves ...\n",
      "   - AI should not be the driver of decisions or source of information. Critical thinking needs to be pro...\n",
      "   - Force all use of ai to be public and transparent ...\n",
      "\n",
      " Cluster 1\n",
      "   - Don't use it to line their pockets and their friends with money...\n",
      "   - Let it be a tool to be used. Don’t let it take the place of humans...\n",
      "   - don't hope AI can do all the job...\n",
      "\n",
      " Cluster 2\n",
      "   - Not sure...\n",
      "   - Be vigilant and do your own research....\n",
      "   - No thoughts ...\n",
      "\n",
      " Cluster 3\n",
      "   - Please don't let this add to our province's energy consumption. If we are going to have data centers...\n",
      "   - Make it accessible and barrier-free for everyone...\n",
      "   - Make it free...\n",
      "\n",
      " Cluster 4\n",
      "   - Take it slow. ...\n",
      "   - Go very, very slow....\n",
      "   - Take it slow ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_data = df['Q17_Advice_BC_Leaders_text_OE'].dropna().astype(str)\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_df=0.9, min_df=3, ngram_range=(1,2))\n",
    "tfidf_matrix = tfidf.fit_transform(text_data)\n",
    "\n",
    "num_clusters = 5 \n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init='auto')\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "\n",
    "df_clustered = text_data.to_frame(name='Response')\n",
    "df_clustered['Cluster'] = kmeans.labels_\n",
    "\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(f\"\\n Cluster {i}\")\n",
    "    sample = df_clustered[df_clustered['Cluster'] == i]['Response'].sample(3, random_state=42)\n",
    "    for resp in sample:\n",
    "        print(f\"   - {resp[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d29c3-1b81-4865-832b-147cfa451e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
